{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1B7hpVGYhAKwIXCZmiL9WpGLRE0l0_CT6","authorship_tag":"ABX9TyN8ZyoLWweljiz9/K/Jumtz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ab7942ff17654bb28caf256765f0a1e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_160138643d344f598aed7c31495af79a","IPY_MODEL_1b8a8884934d4c93a5880b17ad3e6567","IPY_MODEL_811c117948764f1aa468dee9f0bfa303"],"layout":"IPY_MODEL_52990715f8064cfc9b5aea7ea5c5d4ea"}},"160138643d344f598aed7c31495af79a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0f9cc6e820048649637e3d0a9102ef2","placeholder":"​","style":"IPY_MODEL_1c184ece53ce4fb391ab9ab6b351e37c","value":"tokenizer_config.json: 100%"}},"1b8a8884934d4c93a5880b17ad3e6567":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_373df97dd0244aacb7dae3cf3c841193","max":60,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70dd82a845c3444ca70d6bc69afb20eb","value":60}},"811c117948764f1aa468dee9f0bfa303":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ca8c25ec0cc4e9683bd4b43d960c141","placeholder":"​","style":"IPY_MODEL_2fafe47769e54ed1ae2e7417542dc507","value":" 60.0/60.0 [00:00&lt;00:00, 5.73kB/s]"}},"52990715f8064cfc9b5aea7ea5c5d4ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0f9cc6e820048649637e3d0a9102ef2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c184ece53ce4fb391ab9ab6b351e37c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"373df97dd0244aacb7dae3cf3c841193":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70dd82a845c3444ca70d6bc69afb20eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ca8c25ec0cc4e9683bd4b43d960c141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fafe47769e54ed1ae2e7417542dc507":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d057fcf4633a4b9eae1337ba044a777c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d04a1f8563c949e18ccd0324aeae9eb4","IPY_MODEL_ad16d36bdbd64efba3fdcd4ebe5b40f0","IPY_MODEL_396e94be5ab54d07be72871d32e6a735"],"layout":"IPY_MODEL_eca95e7d8a3441b0b0328e3c6b9b4c4c"}},"d04a1f8563c949e18ccd0324aeae9eb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7365421d48164bb99bb80c69f6de3df0","placeholder":"​","style":"IPY_MODEL_6d889d36b134421aae35cbf933abbe68","value":"config.json: 100%"}},"ad16d36bdbd64efba3fdcd4ebe5b40f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e49bf57e95fc4e67a8ccb1b6c53cd898","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9fb6e62042a34d55b639b1658a4c0952","value":385}},"396e94be5ab54d07be72871d32e6a735":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c7ad96938f4470ca2464fc5d2713eac","placeholder":"​","style":"IPY_MODEL_3bb7875ec1de4dacbd5d043dd53485bf","value":" 385/385 [00:00&lt;00:00, 34.3kB/s]"}},"eca95e7d8a3441b0b0328e3c6b9b4c4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7365421d48164bb99bb80c69f6de3df0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d889d36b134421aae35cbf933abbe68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e49bf57e95fc4e67a8ccb1b6c53cd898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fb6e62042a34d55b639b1658a4c0952":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c7ad96938f4470ca2464fc5d2713eac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bb7875ec1de4dacbd5d043dd53485bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dad1a4e6f49d4342aba4abe06f16bfdd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4da579fa484444799231e31db0698c5","IPY_MODEL_9f2a80d098c1445eb809d4f064709936","IPY_MODEL_93af530acbaa4a859aa97387de33df96"],"layout":"IPY_MODEL_0dd3100e436647fbb28c182bf8fac5c0"}},"a4da579fa484444799231e31db0698c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54e630b73e2841e1be8e14a8c78bd4e2","placeholder":"​","style":"IPY_MODEL_101b22800bd44bc7850c843ca4de5d83","value":"vocab.txt: "}},"9f2a80d098c1445eb809d4f064709936":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63810f8a70ad401a911d8bad2c3cf3fe","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa6497bdbe37412bbd4639031ab989f3","value":1}},"93af530acbaa4a859aa97387de33df96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d56e0223842460ebf79e27fbc2f5616","placeholder":"​","style":"IPY_MODEL_c54dc478bb4945c28d669ace05e2c6dd","value":" 251k/? [00:00&lt;00:00, 16.1MB/s]"}},"0dd3100e436647fbb28c182bf8fac5c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54e630b73e2841e1be8e14a8c78bd4e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"101b22800bd44bc7850c843ca4de5d83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63810f8a70ad401a911d8bad2c3cf3fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"aa6497bdbe37412bbd4639031ab989f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d56e0223842460ebf79e27fbc2f5616":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c54dc478bb4945c28d669ace05e2c6dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a199e6186774a08a35f144d374f49ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d376b5bfa61e416abf3f33beaa66fbcc","IPY_MODEL_4830a79ae6e44916a18d396af60048b7","IPY_MODEL_935f05850d5a4bf193c616cc41791ced"],"layout":"IPY_MODEL_1d1392eef6e942fa80d93a47284aedfa"}},"d376b5bfa61e416abf3f33beaa66fbcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bba1d5b8ac3c450c96e2a697f6885d21","placeholder":"​","style":"IPY_MODEL_4cc17e308fb34674a33d0f64d0a4ad1b","value":"model.safetensors: 100%"}},"4830a79ae6e44916a18d396af60048b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_926b91fdbd274712af13e1f365ff032f","max":444996256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2ab11394561468fa3b56230381b5fca","value":444996256}},"935f05850d5a4bf193c616cc41791ced":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbcc0454583748e6b4de6d987ccc995a","placeholder":"​","style":"IPY_MODEL_d0da134692214d99b3f6e7cfda13eb0c","value":" 445M/445M [00:23&lt;00:00, 20.4MB/s]"}},"1d1392eef6e942fa80d93a47284aedfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bba1d5b8ac3c450c96e2a697f6885d21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cc17e308fb34674a33d0f64d0a4ad1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"926b91fdbd274712af13e1f365ff032f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2ab11394561468fa3b56230381b5fca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bbcc0454583748e6b4de6d987ccc995a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0da134692214d99b3f6e7cfda13eb0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#!pip install -q transformers==4.36.2 datasets==2.20.0 scikit-learn==1.4.2 torch torchvision torchaudio\n","\n","import os, json\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils.class_weight import compute_class_weight\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n","from tqdm import tqdm\n","import gc\n","\n","JSON_PATH = \"/content/drive/MyDrive/mava/trendyo_limited2.json\"\n","TEXT_COL = \"title\"\n","LABEL_A = \"ana_kategori\"\n","LABEL_B = \"alt_kategori_1\"\n","LABEL_C = \"alt_kategori_2\"\n","\n","MODEL_NAME = \"dbmdz/bert-base-turkish-cased\"\n","MAX_LEN = 64\n","BATCH_SIZE = 32\n","EPOCHS_WARMUP = 1\n","EPOCHS_FINETUNE = 2\n","LR_HEAD = 3e-4\n","LR_ENCODER = 2e-5\n","SEED = 42\n","\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","gc.collect()\n","torch.cuda.empty_cache() if torch.cuda.is_available() else None"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dawug3jlpyEf","outputId":"1eaf96ca-99f4-4e79-afb7-727606fbb378","executionInfo":{"status":"ok","timestamp":1755559470560,"user_tz":-180,"elapsed":9690,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}]},{"cell_type":"code","source":["df = pd.read_json(JSON_PATH)\n","df[TEXT_COL] = df[TEXT_COL].astype(str).str.strip()\n","\n","enc_a = LabelEncoder()\n","enc_b = LabelEncoder()\n","enc_c = LabelEncoder()\n","\n","y_a = enc_a.fit_transform(df[LABEL_A].astype(str))\n","y_b = enc_b.fit_transform(df[LABEL_B].astype(str))\n","y_c = enc_c.fit_transform(df[LABEL_C].astype(str))\n","\n","num_a = len(enc_a.classes_)\n","num_b = len(enc_b.classes_)\n","num_c = len(enc_c.classes_)\n","\n","print(f\"Sınıf sayıları → ana:{num_a}, alt1:{num_b}, alt2:{num_c}\")\n","\n","os.makedirs(\"/content/drive/MyDrive/mava/artifacts\", exist_ok=True)\n","\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4yB_b-x9Uei","executionInfo":{"status":"ok","timestamp":1755546234709,"user_tz":-180,"elapsed":16217,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"3a058d07-1a8f-4b08-bb61-2165388de563"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Sınıf sayıları → ana:9, alt1:57, alt2:440\n"]},{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["def create_hierarchical_categories(df, enc_a, enc_b, enc_c):\n","    hierarchical_structure = {}\n","\n","    for idx, row in df.iterrows():\n","        ana_cat = row[LABEL_A]\n","        alt1_cat = row[LABEL_B]\n","        alt2_cat = row[LABEL_C]\n","\n","        if ana_cat not in hierarchical_structure:\n","            hierarchical_structure[ana_cat] = {}\n","\n","        if alt1_cat not in hierarchical_structure[ana_cat]:\n","            hierarchical_structure[ana_cat][alt1_cat] = []\n","\n","        if alt2_cat not in hierarchical_structure[ana_cat][alt1_cat]:\n","            hierarchical_structure[ana_cat][alt1_cat].append(alt2_cat)\n","\n","    return hierarchical_structure\n","\n","hierarchical_cats = create_hierarchical_categories(df, enc_a, enc_b, enc_c)\n","\n","with open(\"/content/drive/MyDrive/mava/artifacts/label_maps.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump({\n","        \"hierarchical_categories\": hierarchical_cats,\n","        \"flat_categories\": {\n","            \"ana_kategori\": enc_a.classes_.tolist(),\n","            \"alt_kategori_1\": enc_b.classes_.tolist(),\n","            \"alt_kategori_2\": enc_c.classes_.tolist(),\n","        }\n","    }, f, ensure_ascii=False, indent=2)\n","\n","print(\"Label maps kaydedildi!\")\n","\n","del hierarchical_cats\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLdbFhFG9elG","executionInfo":{"status":"ok","timestamp":1755546273183,"user_tz":-180,"elapsed":36662,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"7fb61d52-cdae-4761-f3ad-26fabb0addfd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Label maps kaydedildi!\n"]},{"output_type":"execute_result","data":{"text/plain":["33"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["train_idx, val_idx = train_test_split(\n","    np.arange(len(df)),\n","    test_size=0.1,\n","    random_state=SEED,\n","    stratify=y_a\n",")\n","\n","df_train = df.iloc[train_idx]\n","df_val = df.iloc[val_idx]\n","y_a_tr, y_a_val = y_a[train_idx], y_a[val_idx]\n","y_b_tr, y_b_val = y_b[train_idx], y_b[val_idx]\n","y_c_tr, y_c_val = y_c[train_idx], y_c[val_idx]\n","\n","print(f\"Train size: {len(df_train)}, Val size: {len(df_val)}\")\n","\n","del df\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rNTuJdTK9egq","executionInfo":{"status":"ok","timestamp":1755546281330,"user_tz":-180,"elapsed":2171,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"e5c28282-534e-443f-faef-3ccf1f958ad8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Train size: 642878, Val size: 71431\n"]},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","class ProductDataset(Dataset):\n","    def __init__(self, texts, labels_a, labels_b, labels_c, tokenizer, max_len):\n","        self.texts = texts\n","        self.labels_a = labels_a\n","        self.labels_b = labels_b\n","        self.labels_c = labels_c\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = str(self.texts.iloc[idx])\n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            truncation=True,\n","            padding='max_length',\n","            max_length=self.max_len,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'label_a': torch.tensor(self.labels_a[idx], dtype=torch.long),\n","            'label_b': torch.tensor(self.labels_b[idx], dtype=torch.long),\n","            'label_c': torch.tensor(self.labels_c[idx], dtype=torch.long)\n","        }\n","\n","print(\"Dataset sınıfı tanımlandı!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289,"referenced_widgets":["ab7942ff17654bb28caf256765f0a1e0","160138643d344f598aed7c31495af79a","1b8a8884934d4c93a5880b17ad3e6567","811c117948764f1aa468dee9f0bfa303","52990715f8064cfc9b5aea7ea5c5d4ea","c0f9cc6e820048649637e3d0a9102ef2","1c184ece53ce4fb391ab9ab6b351e37c","373df97dd0244aacb7dae3cf3c841193","70dd82a845c3444ca70d6bc69afb20eb","8ca8c25ec0cc4e9683bd4b43d960c141","2fafe47769e54ed1ae2e7417542dc507","d057fcf4633a4b9eae1337ba044a777c","d04a1f8563c949e18ccd0324aeae9eb4","ad16d36bdbd64efba3fdcd4ebe5b40f0","396e94be5ab54d07be72871d32e6a735","eca95e7d8a3441b0b0328e3c6b9b4c4c","7365421d48164bb99bb80c69f6de3df0","6d889d36b134421aae35cbf933abbe68","e49bf57e95fc4e67a8ccb1b6c53cd898","9fb6e62042a34d55b639b1658a4c0952","9c7ad96938f4470ca2464fc5d2713eac","3bb7875ec1de4dacbd5d043dd53485bf","dad1a4e6f49d4342aba4abe06f16bfdd","a4da579fa484444799231e31db0698c5","9f2a80d098c1445eb809d4f064709936","93af530acbaa4a859aa97387de33df96","0dd3100e436647fbb28c182bf8fac5c0","54e630b73e2841e1be8e14a8c78bd4e2","101b22800bd44bc7850c843ca4de5d83","63810f8a70ad401a911d8bad2c3cf3fe","aa6497bdbe37412bbd4639031ab989f3","1d56e0223842460ebf79e27fbc2f5616","c54dc478bb4945c28d669ace05e2c6dd"]},"id":"DQU03BAb9ecb","executionInfo":{"status":"ok","timestamp":1755546289361,"user_tz":-180,"elapsed":2770,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"70f9b8f6-44fc-46c0-e063-8b3c1b8573f7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab7942ff17654bb28caf256765f0a1e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d057fcf4633a4b9eae1337ba044a777c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dad1a4e6f49d4342aba4abe06f16bfdd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset sınıfı tanımlandı!\n"]}]},{"cell_type":"code","source":["train_dataset = ProductDataset(\n","    df_train[TEXT_COL], y_a_tr, y_b_tr, y_c_tr, tokenizer, MAX_LEN\n",")\n","val_dataset = ProductDataset(\n","    df_val[TEXT_COL], y_a_val, y_b_val, y_c_val, tokenizer, MAX_LEN\n",")\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","def calc_class_weights(y, num_classes):\n","    cw = compute_class_weight(\n","        class_weight=\"balanced\",\n","        classes=np.arange(num_classes),\n","        y=y\n","    )\n","    return torch.tensor(cw, dtype=torch.float32).to(device)\n","\n","class_weights_a = calc_class_weights(y_a_tr, num_a)\n","class_weights_b = calc_class_weights(y_b_tr, num_b)\n","class_weights_c = calc_class_weights(y_c_tr, num_c)\n","\n","print(f\"DataLoaders hazır - Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n","\n","del df_train, df_val\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJV852ys9sLu","executionInfo":{"status":"ok","timestamp":1755546294515,"user_tz":-180,"elapsed":1732,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"6a637666-4adf-4349-847d-ad40ae52741e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["DataLoaders hazır - Train batches: 20090, Val batches: 2233\n"]},{"output_type":"execute_result","data":{"text/plain":["129"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["class MultiHeadBertClassifier(nn.Module):\n","    def __init__(self, model_name, num_classes_a, num_classes_b, num_classes_c, dropout=0.2):\n","        super(MultiHeadBertClassifier, self).__init__()\n","\n","        self.bert = AutoModel.from_pretrained(model_name)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        hidden_size = self.bert.config.hidden_size\n","        self.proj = nn.Linear(hidden_size, hidden_size)\n","        self.tanh = nn.Tanh()\n","\n","        self.head_a = nn.Linear(hidden_size, num_classes_a)\n","        self.head_b = nn.Linear(hidden_size, num_classes_b)\n","        self.head_c = nn.Linear(hidden_size, num_classes_c)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","\n","        pooled_output = outputs.pooler_output\n","        if pooled_output is None:\n","            pooled_output = outputs.last_hidden_state[:, 0]\n","\n","        x = self.proj(pooled_output)\n","        x = self.tanh(x)\n","        x = self.dropout(x)\n","\n","        logits_a = self.head_a(x)\n","        logits_b = self.head_b(x)\n","        logits_c = self.head_c(x)\n","\n","        return logits_a, logits_b, logits_c\n","\n","print(\"Model sınıfı tanımlandı!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Al6r0R1n9wcR","executionInfo":{"status":"ok","timestamp":1755546298528,"user_tz":-180,"elapsed":17,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"f0ecd382-fc6a-4a69-f880-32c4a398cb57"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model sınıfı tanımlandı!\n"]}]},{"cell_type":"code","source":["model = MultiHeadBertClassifier(MODEL_NAME, num_a, num_b, num_c)\n","model.to(device)\n","\n","criterion_a = nn.CrossEntropyLoss(weight=class_weights_a)\n","criterion_b = nn.CrossEntropyLoss(weight=class_weights_b)\n","criterion_c = nn.CrossEntropyLoss(weight=class_weights_c)\n","\n","print(\"Model GPU'ya yüklendi!\")\n","print(f\"Model parametreleri: {sum(p.numel() for p in model.parameters()):,}\")\n","\n","gc.collect()\n","torch.cuda.empty_cache() if torch.cuda.is_available() else None"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243,"referenced_widgets":["7a199e6186774a08a35f144d374f49ac","d376b5bfa61e416abf3f33beaa66fbcc","4830a79ae6e44916a18d396af60048b7","935f05850d5a4bf193c616cc41791ced","1d1392eef6e942fa80d93a47284aedfa","bba1d5b8ac3c450c96e2a697f6885d21","4cc17e308fb34674a33d0f64d0a4ad1b","926b91fdbd274712af13e1f365ff032f","b2ab11394561468fa3b56230381b5fca","bbcc0454583748e6b4de6d987ccc995a","d0da134692214d99b3f6e7cfda13eb0c"]},"id":"nGP5X9tf91JP","executionInfo":{"status":"ok","timestamp":1755546329804,"user_tz":-180,"elapsed":28787,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"b30cc180-e60b-41b4-819d-b84bda00ab43"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n","  _torch_pytree._register_pytree_node(\n","/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n","  _torch_pytree._register_pytree_node(\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a199e6186774a08a35f144d374f49ac"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model GPU'ya yüklendi!\n","Model parametreleri: 111,597,050\n"]}]},{"cell_type":"code","source":["def train_epoch(model, data_loader, optimizer, scheduler, device, freeze_bert=False):\n","    model.train()\n","    total_loss = 0\n","    correct_a = correct_b = correct_c = 0\n","    total = 0\n","\n","    for batch in tqdm(data_loader):\n","        optimizer.zero_grad()\n","\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels_a = batch['label_a'].to(device)\n","        labels_b = batch['label_b'].to(device)\n","        labels_c = batch['label_c'].to(device)\n","\n","        logits_a, logits_b, logits_c = model(input_ids, attention_mask)\n","\n","        loss_a = criterion_a(logits_a, labels_a)\n","        loss_b = criterion_b(logits_b, labels_b)\n","        loss_c = criterion_c(logits_c, labels_c)\n","        loss = loss_a + loss_b + loss_c\n","\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        total_loss += loss.item()\n","\n","        _, pred_a = torch.max(logits_a.data, 1)\n","        _, pred_b = torch.max(logits_b.data, 1)\n","        _, pred_c = torch.max(logits_c.data, 1)\n","\n","        correct_a += (pred_a == labels_a).sum().item()\n","        correct_b += (pred_b == labels_b).sum().item()\n","        correct_c += (pred_c == labels_c).sum().item()\n","        total += labels_a.size(0)\n","\n","    return (total_loss / len(data_loader),\n","            correct_a / total,\n","            correct_b / total,\n","            correct_c / total)\n","\n","def eval_model(model, data_loader, device):\n","    model.eval()\n","    total_loss = 0\n","    correct_a = correct_b = correct_c = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels_a = batch['label_a'].to(device)\n","            labels_b = batch['label_b'].to(device)\n","            labels_c = batch['label_c'].to(device)\n","\n","            logits_a, logits_b, logits_c = model(input_ids, attention_mask)\n","\n","            loss_a = criterion_a(logits_a, labels_a)\n","            loss_b = criterion_b(logits_b, labels_b)\n","            loss_c = criterion_c(logits_c, labels_c)\n","            loss = loss_a + loss_b + loss_c\n","\n","            total_loss += loss.item()\n","\n","            _, pred_a = torch.max(logits_a.data, 1)\n","            _, pred_b = torch.max(logits_b.data, 1)\n","            _, pred_c = torch.max(logits_c.data, 1)\n","\n","            correct_a += (pred_a == labels_a).sum().item()\n","            correct_b += (pred_b == labels_b).sum().item()\n","            correct_c += (pred_c == labels_c).sum().item()\n","            total += labels_a.size(0)\n","\n","    return (total_loss / len(data_loader),\n","            correct_a / total,\n","            correct_b / total,\n","            correct_c / total)\n","\n","print(\"Training fonksiyonları tanımlandı!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jsFdFYZo95jb","executionInfo":{"status":"ok","timestamp":1755546331798,"user_tz":-180,"elapsed":25,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"0c249e3a-68c5-458d-de7a-30f2cfd71e1a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Training fonksiyonları tanımlandı!\n"]}]},{"cell_type":"code","source":["if EPOCHS_WARMUP > 0:\n","    print(\"Phase 1: Warmup (BERT frozen) başlıyor...\")\n","\n","    for param in model.bert.parameters():\n","        param.requires_grad = False\n","\n","    head_params = list(model.proj.parameters()) + list(model.head_a.parameters()) + \\\n","                  list(model.head_b.parameters()) + list(model.head_c.parameters())\n","\n","    optimizer_warmup = optim.Adam(head_params, lr=LR_HEAD)\n","    scheduler_warmup = get_linear_schedule_with_warmup(\n","        optimizer_warmup,\n","        num_warmup_steps=0,\n","        num_training_steps=len(train_loader) * EPOCHS_WARMUP\n","    )\n","\n","    best_acc = 0\n","    for epoch in range(EPOCHS_WARMUP):\n","        print(f\"\\nWarmup Epoch {epoch+1}/{EPOCHS_WARMUP}\")\n","\n","        train_loss, train_acc_a, train_acc_b, train_acc_c = train_epoch(\n","            model, train_loader, optimizer_warmup, scheduler_warmup, device\n","        )\n","        val_loss, val_acc_a, val_acc_b, val_acc_c = eval_model(model, val_loader, device)\n","\n","        print(f'Train Loss: {train_loss:.4f}, Train Acc A: {train_acc_a:.4f}')\n","        print(f'Val Loss: {val_loss:.4f}, Val Acc A: {val_acc_a:.4f}')\n","\n","        if val_acc_a > best_acc:\n","            best_acc = val_acc_a\n","            torch.save(model.state_dict(), '/content/drive/MyDrive/mava/artifacts/model_warmup.pth')\n","            print(\"Warmup model kaydedildi!\")\n","\n","    del optimizer_warmup, scheduler_warmup\n","    gc.collect()\n","    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n","\n","    print(\"Warmup phase tamamlandı!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfxp8Ajw99QO","executionInfo":{"status":"ok","timestamp":1755548971132,"user_tz":-180,"elapsed":2636562,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"330cdb9e-a366-49e6-89ea-8e4f09efc1fc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Phase 1: Warmup (BERT frozen) başlıyor...\n","\n","Warmup Epoch 1/1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20090/20090 [39:36<00:00,  8.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 10.5967, Train Acc A: 0.3436\n","Val Loss: 8.9240, Val Acc A: 0.5122\n","Warmup model kaydedildi!\n","Warmup phase tamamlandı!\n"]}]},{"cell_type":"code","source":["if EPOCHS_FINETUNE > 0:\n","    print(\"Phase 2: Fine-tuning (BERT unfrozen) başlıyor...\")\n","\n","    for param in model.bert.parameters():\n","        param.requires_grad = True\n","\n","    optimizer_finetune = optim.Adam([\n","        {'params': model.bert.parameters(), 'lr': LR_ENCODER},\n","        {'params': model.proj.parameters(), 'lr': LR_HEAD},\n","        {'params': model.head_a.parameters(), 'lr': LR_HEAD},\n","        {'params': model.head_b.parameters(), 'lr': LR_HEAD},\n","        {'params': model.head_c.parameters(), 'lr': LR_HEAD}\n","    ])\n","\n","    scheduler_finetune = get_linear_schedule_with_warmup(\n","        optimizer_finetune,\n","        num_warmup_steps=0,\n","        num_training_steps=len(train_loader) * EPOCHS_FINETUNE\n","    )\n","\n","    best_acc = 0\n","    for epoch in range(EPOCHS_FINETUNE):\n","        print(f\"\\nFine-tune Epoch {epoch+1}/{EPOCHS_FINETUNE}\")\n","\n","        train_loss, train_acc_a, train_acc_b, train_acc_c = train_epoch(\n","            model, train_loader, optimizer_finetune, scheduler_finetune, device\n","        )\n","        val_loss, val_acc_a, val_acc_b, val_acc_c = eval_model(model, val_loader, device)\n","\n","        print(f'Train Loss: {train_loss:.4f}, Train Acc A: {train_acc_a:.4f}')\n","        print(f'Val Loss: {val_loss:.4f}, Val Acc A: {val_acc_a:.4f}')\n","\n","        if val_acc_a > best_acc:\n","            best_acc = val_acc_a\n","            torch.save(model.state_dict(), '/content/drive/MyDrive/mava/artifacts/model_finetune.pth')\n","            print(\"Fine-tune model kaydedildi!\")\n","\n","    del optimizer_finetune, scheduler_finetune\n","    gc.collect()\n","    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n","\n","    print(\"Fine-tuning phase tamamlandı!\")"],"metadata":{"id":"jckjtXLI-B4t","colab":{"base_uri":"https://localhost:8080/"},"outputId":"075621b3-921c-44e4-cd78-8d40da6b2c53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Phase 2: Fine-tuning (BERT unfrozen) başlıyor...\n","\n","Fine-tune Epoch 1/2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20090/20090 [1:51:36<00:00,  3.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 2.7588, Train Acc A: 0.8682\n","Val Loss: 1.8453, Val Acc A: 0.9164\n","Fine-tune model kaydedildi!\n","\n","Fine-tune Epoch 2/2\n"]},{"output_type":"stream","name":"stderr","text":[" 41%|████      | 8182/20090 [45:26<1:05:32,  3.03it/s]"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/mava/artifacts/berturk_multihead_pytorch.pth')\n","print(\"Final model kaydedildi!\")\n","\n","id2a = {i: c for i, c in enumerate(enc_a.classes_)}\n","id2b = {i: c for i, c in enumerate(enc_b.classes_)}\n","id2c = {i: c for i, c in enumerate(enc_c.classes_)}\n","\n","def predict_titles(titles, topk=1):\n","    model.eval()\n","    results = []\n","\n","    with torch.no_grad():\n","        for title in titles:\n","            encoding = tokenizer.encode_plus(\n","                title,\n","                truncation=True,\n","                padding='max_length',\n","                max_length=MAX_LEN,\n","                return_tensors='pt'\n","            )\n","\n","            input_ids = encoding['input_ids'].to(device)\n","            attention_mask = encoding['attention_mask'].to(device)\n","\n","            logits_a, logits_b, logits_c = model(input_ids, attention_mask)\n","\n","            probs_a = torch.softmax(logits_a, dim=1).cpu().numpy()[0]\n","            probs_b = torch.softmax(logits_b, dim=1).cpu().numpy()[0]\n","            probs_c = torch.softmax(logits_c, dim=1).cpu().numpy()[0]\n","\n","            top_a = np.argsort(probs_a)[::-1][:topk]\n","            top_b = np.argsort(probs_b)[::-1][:topk]\n","            top_c = np.argsort(probs_c)[::-1][:topk]\n","\n","            results.append({\n","                \"title\": title,\n","                \"ana_top\": [(id2a[j], float(probs_a[j])) for j in top_a],\n","                \"alt1_top\": [(id2b[j], float(probs_b[j])) for j in top_b],\n","                \"alt2_top\": [(id2c[j], float(probs_c[j])) for j in top_c],\n","            })\n","\n","    return results\n","\n","print(\"Prediction fonksiyonu hazır!\")"],"metadata":{"id":"NpG14zSv-GQe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755559509795,"user_tz":-180,"elapsed":16,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"601096c6-2a92-4a9b-ee03-947fc72f5338"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction fonksiyonu hazır!\n"]}]},{"cell_type":"code","source":["# COMPLETE RESUME SCRIPT - Yeni session için\n","import os, json\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils.class_weight import compute_class_weight\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n","from tqdm import tqdm\n","import gc\n","\n","CSV_PATH = \"/content/drive/MyDrive/mava/trendyo_limited2.json\"\n","TEXT_COL = \"title\"\n","LABEL_A = \"ana_kategori\"\n","LABEL_B = \"alt_kategori_1\"\n","LABEL_C = \"alt_kategori_2\"\n","\n","MODEL_NAME = \"dbmdz/bert-base-turkish-cased\"\n","MAX_LEN = 64\n","BATCH_SIZE = 32\n","EPOCHS_WARMUP = 1\n","EPOCHS_FINETUNE = 2\n","LR_HEAD = 3e-4\n","LR_ENCODER = 2e-5\n","SEED = 42\n","\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device: {device}\")\n","\n","print(\"Label maps yükleniyor...\")\n","with open(\"/content/drive/MyDrive/mava/artifacts/label_maps.json\", \"r\", encoding=\"utf-8\") as f:\n","    label_maps = json.load(f)\n","\n","enc_a = LabelEncoder()\n","enc_b = LabelEncoder()\n","enc_c = LabelEncoder()\n","enc_a.classes_ = np.array(label_maps[\"flat_categories\"][\"ana_kategori\"])\n","enc_b.classes_ = np.array(label_maps[\"flat_categories\"][\"alt_kategori_1\"])\n","enc_c.classes_ = np.array(label_maps[\"flat_categories\"][\"alt_kategori_2\"])\n","\n","num_a, num_b, num_c = len(enc_a.classes_), len(enc_b.classes_), len(enc_c.classes_)\n","print(f\"Sınıf sayıları → ana:{num_a}, alt1:{num_b}, alt2:{num_c}\")\n","\n","df = pd.read_json(CSV_PATH)\n","df[TEXT_COL] = df[TEXT_COL].astype(str).str.strip()\n","\n","y_a = enc_a.transform(df[LABEL_A].astype(str))\n","y_b = enc_b.transform(df[LABEL_B].astype(str))\n","y_c = enc_c.transform(df[LABEL_C].astype(str))\n","\n","train_idx, val_idx = train_test_split(\n","    np.arange(len(df)), test_size=0.1, random_state=SEED, stratify=y_a\n",")\n","\n","df_train = df.iloc[train_idx]\n","df_val = df.iloc[val_idx]\n","y_a_tr, y_a_val = y_a[train_idx], y_a[val_idx]\n","y_b_tr, y_b_val = y_b[train_idx], y_b[val_idx]\n","y_c_tr, y_c_val = y_c[train_idx], y_c[val_idx]\n","\n","del df\n","gc.collect()\n","print(f\"Train: {len(df_train)}, Val: {len(df_val)}\")\n","\n","print(\"Tokenizer yükleniyor...\")\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","class ProductDataset(Dataset):\n","    def __init__(self, texts, labels_a, labels_b, labels_c, tokenizer, max_len):\n","        self.texts = texts\n","        self.labels_a = labels_a\n","        self.labels_b = labels_b\n","        self.labels_c = labels_c\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = str(self.texts.iloc[idx])\n","        encoding = self.tokenizer.encode_plus(\n","            text, truncation=True, padding='max_length',\n","            max_length=self.max_len, return_tensors='pt'\n","        )\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'label_a': torch.tensor(self.labels_a[idx], dtype=torch.long),\n","            'label_b': torch.tensor(self.labels_b[idx], dtype=torch.long),\n","            'label_c': torch.tensor(self.labels_c[idx], dtype=torch.long)\n","        }\n","\n","train_dataset = ProductDataset(df_train[TEXT_COL], y_a_tr, y_b_tr, y_c_tr, tokenizer, MAX_LEN)\n","val_dataset = ProductDataset(df_val[TEXT_COL], y_a_val, y_b_val, y_c_val, tokenizer, MAX_LEN)\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","del df_train, df_val\n","gc.collect()\n","\n","def calc_class_weights(y, num_classes):\n","    cw = compute_class_weight(\"balanced\", classes=np.arange(num_classes), y=y)\n","    return torch.tensor(cw, dtype=torch.float32).to(device)\n","\n","class_weights_a = calc_class_weights(y_a_tr, num_a)\n","class_weights_b = calc_class_weights(y_b_tr, num_b)\n","class_weights_c = calc_class_weights(y_c_tr, num_c)\n","\n","class MultiHeadBertClassifier(nn.Module):\n","    def __init__(self, model_name, num_classes_a, num_classes_b, num_classes_c, dropout=0.2):\n","        super(MultiHeadBertClassifier, self).__init__()\n","        self.bert = AutoModel.from_pretrained(model_name)\n","        self.dropout = nn.Dropout(dropout)\n","        hidden_size = self.bert.config.hidden_size\n","        self.proj = nn.Linear(hidden_size, hidden_size)\n","        self.tanh = nn.Tanh()\n","        self.head_a = nn.Linear(hidden_size, num_classes_a)\n","        self.head_b = nn.Linear(hidden_size, num_classes_b)\n","        self.head_c = nn.Linear(hidden_size, num_classes_c)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.pooler_output\n","        if pooled_output is None:\n","            pooled_output = outputs.last_hidden_state[:, 0]\n","        x = self.proj(pooled_output)\n","        x = self.tanh(x)\n","        x = self.dropout(x)\n","        return self.head_a(x), self.head_b(x), self.head_c(x)\n","\n","print(\"Model yükleniyor...\")\n","model = MultiHeadBertClassifier(MODEL_NAME, num_a, num_b, num_c)\n","model.to(device)\n","\n","criterion_a = nn.CrossEntropyLoss(weight=class_weights_a)\n","criterion_b = nn.CrossEntropyLoss(weight=class_weights_b)\n","criterion_c = nn.CrossEntropyLoss(weight=class_weights_c)\n","\n","id2a = {i: c for i, c in enumerate(enc_a.classes_)}\n","id2b = {i: c for i, c in enumerate(enc_b.classes_)}\n","id2c = {i: c for i, c in enumerate(enc_c.classes_)}\n","\n","print(f\"Model GPU'da: {next(model.parameters()).device}\")\n","gc.collect()\n","torch.cuda.empty_cache() if torch.cuda.is_available() else None"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DjtFyEMVgJHK","executionInfo":{"status":"ok","timestamp":1755560066985,"user_tz":-180,"elapsed":15167,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"f8e6358b-6299-4c50-dc43-03276218feef"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cpu\n","Label maps yükleniyor...\n","Sınıf sayıları → ana:9, alt1:57, alt2:440\n","Train: 642878, Val: 71431\n","Tokenizer yükleniyor...\n","Model yükleniyor...\n","Model GPU'da: cpu\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device: {device}\")\n","\n","if torch.cuda.is_available():\n","    model.load_state_dict(torch.load('/content/drive/MyDrive/mava/artifacts/model_finetune.pth'))\n","else:\n","    model.load_state_dict(torch.load('/content/drive/MyDrive/mava/artifacts/model_finetune.pth',\n","                                    map_location=torch.device('cpu')))\n","\n","model.to(device)\n","print(f\"Model yüklendi ve {device}'a taşındı!\")\n","\n","def predict_titles(titles, topk=1):\n","    model.eval()\n","    results = []\n","    with torch.no_grad():\n","        for title in titles:\n","            encoding = tokenizer.encode_plus(\n","                title, truncation=True, padding='max_length',\n","                max_length=MAX_LEN, return_tensors='pt'\n","            )\n","            input_ids = encoding['input_ids'].to(device)\n","            attention_mask = encoding['attention_mask'].to(device)\n","\n","            logits_a, logits_b, logits_c = model(input_ids, attention_mask)\n","\n","            probs_a = torch.softmax(logits_a, dim=1).cpu().numpy()[0]\n","            probs_b = torch.softmax(logits_b, dim=1).cpu().numpy()[0]\n","            probs_c = torch.softmax(logits_c, dim=1).cpu().numpy()[0]\n","\n","            top_a = np.argsort(probs_a)[::-1][:topk]\n","            top_b = np.argsort(probs_b)[::-1][:topk]\n","            top_c = np.argsort(probs_c)[::-1][:topk]\n","\n","            results.append({\n","                \"title\": title,\n","                \"ana_top\": [(id2a[j], float(probs_a[j])) for j in top_a],\n","                \"alt1_top\": [(id2b[j], float(probs_b[j])) for j in top_b],\n","                \"alt2_top\": [(id2c[j], float(probs_c[j])) for j in top_c],\n","            })\n","    return results\n","\n","sample_titles = [\n","    \"bebek bezi \",\n","    \"mitoloji kitap\",\n","    \" kadın gümüş kolye\",\n","    \"erkek gümüş kolye\",\n","    \"bulaşık makinesi yedek parça\",\n","    \"renkli tablo\",\n","    \"sandalye mutfak 4lü\"\n","]\n","\n","print(\"Test başlıyor...\")\n","preds = predict_titles(sample_titles, topk=3)\n","\n","for p in preds:\n","    print(f\"\\n  {p['title']}\")\n","    print(f\"ANA: {p['ana_top'][0][0]} ({p['ana_top'][0][1]:.3f})\")\n","    print(f\"ALT1: {p['alt1_top'][0][0]} ({p['alt1_top'][0][1]:.3f})\")\n","    print(f\"ALT2: {p['alt2_top'][0][0]} ({p['alt2_top'][0][1]:.3f})\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aW614-Smg2Eq","executionInfo":{"status":"ok","timestamp":1755560131145,"user_tz":-180,"elapsed":2238,"user":{"displayName":"Süleyman Emre Parlak","userId":"13214908082485500936"}},"outputId":"02857f0a-43ad-4b34-af3d-292e12e47acc"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cpu\n","Model yüklendi ve cpu'a taşındı!\n","Test başlıyor...\n","\n","  bebek bezi \n","ANA: Anne & Çocuk (0.984)\n","ALT1: Bebek Bakım (0.910)\n","ALT2: Bebek Bakım ve Kozmetik (0.632)\n","\n","  mitoloji kitap\n","ANA: Kitap & Kırtasiye & Hobi (0.998)\n","ALT1: Din Ve Mitoloji (0.836)\n","ALT2: Mitoloji (0.968)\n","\n","   kadın gümüş kolye\n","ANA: Kadın (0.687)\n","ALT1: Aksesuar (0.961)\n","ALT2: Takı & Mücevher (0.459)\n","\n","  erkek gümüş kolye\n","ANA: Erkek (0.996)\n","ALT1: Aksesuar (0.991)\n","ALT2: Takı & Mücevher (0.971)\n","\n","  bulaşık makinesi yedek parça\n","ANA: Elektronik (0.576)\n","ALT1: Beyaz Eşya (0.661)\n","ALT2: Bulaşık Yıkama (0.360)\n","\n","  renkli tablo\n","ANA: Ev & Mobilya (0.974)\n","ALT1: Ev Dekorasyon (0.935)\n","ALT2: Duvar Dekorasyon Ürünü (0.426)\n","\n","  sandalye mutfak 4lü\n","ANA: Ev & Mobilya (0.977)\n","ALT1: Mobilya (0.996)\n","ALT2: Yemek Odası (0.571)\n"]}]}]}